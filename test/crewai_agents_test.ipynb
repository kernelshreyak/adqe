{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from crewai import Agent, Crew, Process,Task\n",
    "from crewai.project import CrewBase, agent, crew\n",
    "from crewai.tools import tool\n",
    "import requests\n",
    "import os\n",
    "import yaml\n",
    "from langtrace_python_sdk import langtrace\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "import builtins\n",
    "\n",
    "@tool(\"filecheck\")\n",
    "def filecheck(file_path: str) -> str:\n",
    "    \"\"\"Check if a file exists at the given path.\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        return \"File exists\"\n",
    "    else:\n",
    "        return \"File does not exist\"   \n",
    "        \n",
    "@tool(\"download_data\")\n",
    "def download_data(data_url: str) -> str:\n",
    "    \"\"\"Download data from a given URL and save it to a local file.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(data_url, stream=True)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "\n",
    "        # Extract filename from URL\n",
    "        filename = data_url.split(\"/\")[-1]\n",
    "        local_file = os.path.join(os.getcwd(), filename)\n",
    "        \n",
    "        # check if file exists\n",
    "        if os.path.exists(local_file):\n",
    "            return local_file\n",
    "\n",
    "        # Save file locally\n",
    "        with open(local_file, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "\n",
    "        return local_file  # Return the path of the downloaded file\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error downloading file: {e}\"\n",
    "\n",
    "@tool(\"json_to_dataframe\")\n",
    "def json_to_dataframe(json_data: str):\n",
    "    \"\"\"Convert a JSON string into a Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_json(json_data)\n",
    "        return data\n",
    "    except ValueError as e:\n",
    "        return f\"Error parsing JSON: {e}\"\n",
    "\n",
    "\n",
    "@tool(\"execute_python_code\")\n",
    "def execute_python_code(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute custom Python code (Pandas/Numpy compatible) and return the printed output.\n",
    "    \"\"\"\n",
    "    # Capture standard output\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "    try:\n",
    "        exec(code, {\"pd\": pd, \"np\": np})  # Execute with Pandas & Numpy in the global scope\n",
    "        output = sys.stdout.getvalue()  # Get printed output\n",
    "    except Exception as e:\n",
    "        output = f\"Error executing code: {e}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout  # Restore original stdout\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define agents, tasks and crew\n",
    "\n",
    "agents_data = None\n",
    "with open(\"../agents.yaml\", 'r') as file:\n",
    "    agents_data = yaml.safe_load(file)\n",
    "    \n",
    "# define agents\n",
    "coordinator_agent = Agent(\n",
    "    config=agents_data['coordinator'],\n",
    "    verbose=True,\n",
    "    tools=[filecheck],\n",
    "    allow_delegation=True,\n",
    "    llm=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "data_downloader_agent = Agent(\n",
    "    config=agents_data['data_downloader'],\n",
    "    verbose=True,\n",
    "    tools=[download_data],\n",
    "    allow_delegation=False,\n",
    "    llm=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "data_analyst_agent = Agent(\n",
    "    config=agents_data['data_analyst'],\n",
    "    verbose=True,\n",
    "    tools=[json_to_dataframe,execute_python_code],\n",
    "    allow_delegation=False,\n",
    "    llm=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "# define tasks\n",
    "analysis_task = Task(\n",
    "    description=\"\"\"\n",
    "        Analyze the data present at {data_source_url} and perform tasks neccessary to answer the user query: {user_query}\n",
    "    \"\"\",\n",
    "    expected_output=\"\"\"\n",
    "        A data analysis report in text as per the user query\n",
    "    \"\"\",\n",
    "    agent=coordinator_agent\n",
    ")\n",
    "crew = Crew(\n",
    "    agents=[coordinator_agent,data_downloader_agent,data_analyst_agent],\n",
    "    tasks=[analysis_task],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:51][ðŸš€ CREW 'CREW' STARTED, 70143AF7-BF89-467C-BFA1-54FFDB675E2E]: 2025-03-10 20:45:51.929298\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:51][ðŸ“‹ TASK STARTED: \n",
      "        ANALYZE THE DATA PRESENT AT HTTPS://RAW.GITHUBUSERCONTENT.COM/KERNELSHREYAK/AI-ML-LEARNING/REFS/HEADS/MASTER/DATASCIENCE/DATASETS/SCOOBYDOO.CSV AND PERFORM TASKS NECCESSARY TO ANSWER THE USER QUERY: USE THIS DATA AND FIND THE TITLE HAVING MAXMIUM IMDB RATING. USE COLUMN: IMDB\n",
      "    ]: 2025-03-10 20:45:51.967655\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:51][ðŸ¤– AGENT 'COORDINATOR\n",
      "' STARTED TASK]: 2025-03-10 20:45:51.973788\u001b[00m\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCoordinator\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m\n",
      "        Analyze the data present at https://raw.githubusercontent.com/kernelshreyak/ai-ml-learning/refs/heads/master/datascience/datasets/scoobydoo.csv and perform tasks neccessary to answer the user query: Use this data and find the title having maxmium imdb rating. Use column: imdb\n",
      "    \u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:51][ðŸ¤– LLM CALL STARTED]: 2025-03-10 20:45:51.974604\u001b[00m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:54][âœ… LLM CALL COMPLETED]: 2025-03-10 20:45:54.917144\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:54][ðŸ¤– TOOL USAGE STARTED: 'DELEGATE WORK TO COWORKER']: 2025-03-10 20:45:54.918091\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:54][ðŸ¤– AGENT 'DATA DOWNLOADER\n",
      "' STARTED TASK]: 2025-03-10 20:45:54.930678\u001b[00m\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Downloader\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mDownload the data file from the provided URL and provide the local file path.\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:54][ðŸ¤– LLM CALL STARTED]: 2025-03-10 20:45:54.931189\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:57][âœ… LLM CALL COMPLETED]: 2025-03-10 20:45:57.137762\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:57][ðŸ¤– TOOL USAGE STARTED: 'DOWNLOAD_DATA']: 2025-03-10 20:45:57.138793\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:57][âœ… TOOL USAGE FINISHED: 'DOWNLOAD_DATA']: 2025-03-10 20:45:57.150956\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Downloader\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mdownload_data\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"data_url\\\": \\\"https://raw.githubusercontent.com/kernelshreyak/ai-ml-learning/refs/heads/master/datascience/datasets/scoobydoo.csv\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "/home/shreyak/programming/agentic-data-query-engine/test/scoobydoo.csv\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:57][ðŸ¤– LLM CALL STARTED]: 2025-03-10 20:45:57.151951\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:58][âœ… LLM CALL COMPLETED]: 2025-03-10 20:45:58.367166\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Downloader\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "The data file has been downloaded and is located at /home/shreyak/programming/agentic-data-query-engine/test/scoobydoo.csv.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:58][âœ… AGENT 'DATA DOWNLOADER\n",
      "' COMPLETED TASK]: 2025-03-10 20:45:58.368412\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:58][âœ… TOOL USAGE FINISHED: 'DELEGATE WORK TO COWORKER']: 2025-03-10 20:45:58.380896\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCoordinator\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: The data is located at a URL. I need to delegate the task to the Data Downloader to obtain the file. Once the file is downloaded, I will delegate the task to the Data Analyst to analyze the data and find the title with the maximum IMDb rating.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"task\\\": \\\"Download the data file from the provided URL and provide the local file path.\\\", \\\"context\\\": \\\"The data is located at the following URL: https://raw.githubusercontent.com/kernelshreyak/ai-ml-learning/refs/heads/master/datascience/datasets/scoobydoo.csv\\\", \\\"coworker\\\": \\\"Data Downloader\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "The data file has been downloaded and is located at /home/shreyak/programming/agentic-data-query-engine/test/scoobydoo.csv.\n",
      "\n",
      "\n",
      "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
      "\n",
      "Tool Name: filecheck\n",
      "Tool Arguments: {'file_path': {'description': None, 'type': 'str'}}\n",
      "Tool Description: Check if a file exists at the given path.\n",
      "Tool Name: Delegate work to coworker\n",
      "Tool Arguments: {'task': {'description': 'The task to delegate', 'type': 'str'}, 'context': {'description': 'The context for the task', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to delegate to', 'type': 'str'}}\n",
      "Tool Description: Delegate a specific task to one of the following coworkers: Data Downloader\n",
      ", Data Analyst\n",
      "\n",
      "The input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolutely everything you know, don't reference things but instead explain them.\n",
      "Tool Name: Ask question to coworker\n",
      "Tool Arguments: {'question': {'description': 'The question to ask', 'type': 'str'}, 'context': {'description': 'The context for the question', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to ask', 'type': 'str'}}\n",
      "Tool Description: Ask a specific question to one of the following coworkers: Data Downloader\n",
      ", Data Analyst\n",
      "\n",
      "The input to this tool should be the coworker, the question you have for them, and ALL necessary context to ask the question properly, they know nothing about the question, so share absolutely everything you know, don't reference things but instead explain them.\n",
      "\n",
      "IMPORTANT: Use the following format in your response:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, only one name of [filecheck, Delegate work to coworker, Ask question to coworker], just the name, exactly as it's written.\n",
      "Action Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "Once all necessary information is gathered, return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "```\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:45:58][ðŸ¤– LLM CALL STARTED]: 2025-03-10 20:45:58.381794\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:00][âœ… LLM CALL COMPLETED]: 2025-03-10 20:46:00.863409\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:00][ðŸ¤– TOOL USAGE STARTED: 'DELEGATE WORK TO COWORKER']: 2025-03-10 20:46:00.864330\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:00][ðŸ¤– AGENT 'DATA ANALYST\n",
      "' STARTED TASK]: 2025-03-10 20:46:00.888557\u001b[00m\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Analyst\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the data to find the title with the maximum IMDb rating using the column 'imdb'.\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:00][ðŸ¤– LLM CALL STARTED]: 2025-03-10 20:46:00.889510\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:03][âœ… LLM CALL COMPLETED]: 2025-03-10 20:46:03.114571\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:03][ðŸ¤– TOOL USAGE STARTED: 'EXECUTE_PYTHON_CODE']: 2025-03-10 20:46:03.115933\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:03][âœ… TOOL USAGE FINISHED: 'EXECUTE_PYTHON_CODE']: 2025-03-10 20:46:03.357679\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Analyst\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mexecute_python_code\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"code\\\": \\\"import pandas as pd\\\\n\\\\ndf = pd.read_csv('https://raw.githubusercontent.com/kernelshreyak/ai-ml-learning/refs/heads/master/datascience/datasets/scoobydoo.csv')\\\\nprint(df.head())\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "   index                 series_name network season  \\\n",
      "0      1  Scooby Doo, Where Are You!     CBS      1   \n",
      "1      2  Scooby Doo, Where Are You!     CBS      1   \n",
      "2      3  Scooby Doo, Where Are You!     CBS      1   \n",
      "3      4  Scooby Doo, Where Are You!     CBS      1   \n",
      "4      5  Scooby Doo, Where Are You!     CBS      1   \n",
      "\n",
      "                       title  imdb  engagement  date_aired  run_time  \\\n",
      "0  What a Night for a Knight   8.1       556.0  1969-09-13        21   \n",
      "1      A Clue for Scooby Doo   8.1       479.0  1969-09-20        22   \n",
      "2       Hassle in the Castle   8.0       455.0  1969-09-27        21   \n",
      "3     Mine Your Own Business   7.8       426.0  1969-10-04        21   \n",
      "4      Decoy for a Dognapper   7.5       391.0  1969-10-11        21   \n",
      "\n",
      "      format  ... batman scooby_dum scrappy_doo hex_girls blue_falcon  \\\n",
      "0  TV Series  ...  False      False       False     False       False   \n",
      "1  TV Series  ...  False      False       False     False       False   \n",
      "2  TV Series  ...  False      False       False     False       False   \n",
      "3  TV Series  ...  False      False       False     False       False   \n",
      "4  TV Series  ...  False      False       False     False       False   \n",
      "\n",
      "        fred_va                  daphnie_va      velma_va    shaggy_va  \\\n",
      "0  Frank Welker  Stefanianna Christopherson  Nicole Jaffe  Casey Kasem   \n",
      "1  Frank Welker  Stefanianna Christopherson  Nicole Jaffe  Casey Kasem   \n",
      "2  Frank Welker  Stefanianna Christopherson  Nicole Jaffe  Casey Kasem   \n",
      "3  Frank Welker  Stefanianna Christopherson  Nicole Jaffe  Casey Kasem   \n",
      "4  Frank Welker  Stefanianna Christopherson  Nicole Jaffe  Casey Kasem   \n",
      "\n",
      "     scooby_va  \n",
      "0  Don Messick  \n",
      "1  Don Messick  \n",
      "2  Don Messick  \n",
      "3  Don Messick  \n",
      "4  Don Messick  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:03][ðŸ¤– LLM CALL STARTED]: 2025-03-10 20:46:03.358619\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:05][âœ… LLM CALL COMPLETED]: 2025-03-10 20:46:05.667875\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:05][ðŸ¤– TOOL USAGE STARTED: 'EXECUTE_PYTHON_CODE']: 2025-03-10 20:46:05.670320\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:05][âœ… TOOL USAGE FINISHED: 'EXECUTE_PYTHON_CODE']: 2025-03-10 20:46:05.680169\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Analyst\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mexecute_python_code\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"code\\\": \\\"max_imdb = df['imdb'].max()\\\\nmax_title = df[df['imdb'] == max_imdb]['title'].iloc[0]\\\\nprint(max_title, max_imdb)\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Error executing code: name 'df' is not defined\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:05][ðŸ¤– LLM CALL STARTED]: 2025-03-10 20:46:05.682580\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:07][âœ… LLM CALL COMPLETED]: 2025-03-10 20:46:07.822330\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:07][ðŸ¤– TOOL USAGE STARTED: 'EXECUTE_PYTHON_CODE']: 2025-03-10 20:46:07.824190\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:07][âœ… TOOL USAGE FINISHED: 'EXECUTE_PYTHON_CODE']: 2025-03-10 20:46:07.972736\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Analyst\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mexecute_python_code\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"code\\\": \\\"import pandas as pd\\\\n\\\\ndf = pd.read_csv('https://raw.githubusercontent.com/kernelshreyak/ai-ml-learning/refs/heads/master/datascience/datasets/scoobydoo.csv')\\\\nmax_imdb = df['imdb'].max()\\\\nmax_title = df[df['imdb'] == max_imdb]['title'].iloc[0]\\\\nprint(max_title, max_imdb)\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Scoobynatural 9.6\n",
      "\n",
      "\n",
      "\n",
      "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
      "\n",
      "Tool Name: json_to_dataframe\n",
      "Tool Arguments: {'json_data': {'description': None, 'type': 'str'}}\n",
      "Tool Description: Convert a JSON string into a Pandas DataFrame.\n",
      "Tool Name: execute_python_code\n",
      "Tool Arguments: {'code': {'description': None, 'type': 'str'}}\n",
      "Tool Description: \n",
      "    Execute custom Python code (Pandas/Numpy compatible) and return the printed output.\n",
      "    \n",
      "\n",
      "IMPORTANT: Use the following format in your response:\n",
      "\n",
      "```\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, only one name of [json_to_dataframe, execute_python_code], just the name, exactly as it's written.\n",
      "Action Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "Once all necessary information is gathered, return the following format:\n",
      "\n",
      "```\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "```\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:07][ðŸ¤– LLM CALL STARTED]: 2025-03-10 20:46:07.973905\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:09][âœ… LLM CALL COMPLETED]: 2025-03-10 20:46:09.307661\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mData Analyst\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "The title with the maximum IMDb rating is \"Scoobynatural\" with an IMDb score of 9.6.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:09][âœ… AGENT 'DATA ANALYST\n",
      "' COMPLETED TASK]: 2025-03-10 20:46:09.308478\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:09][âœ… TOOL USAGE FINISHED: 'DELEGATE WORK TO COWORKER']: 2025-03-10 20:46:09.344058\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCoordinator\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: The data file has been successfully downloaded to a local path. Now, I need to delegate the task to the Data Analyst to analyze the data and find the title with the maximum IMDb rating using the specified column.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"task\\\": \\\"Analyze the data to find the title with the maximum IMDb rating using the column 'imdb'.\\\", \\\"context\\\": \\\"The data file is located at /home/shreyak/programming/agentic-data-query-engine/test/scoobydoo.csv and the user query is to find the title having maximum imdb rating using the column 'imdb'.\\\", \\\"coworker\\\": \\\"Data Analyst\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "The title with the maximum IMDb rating is \"Scoobynatural\" with an IMDb score of 9.6.\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:09][ðŸ¤– LLM CALL STARTED]: 2025-03-10 20:46:09.344914\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:10][âœ… LLM CALL COMPLETED]: 2025-03-10 20:46:10.893262\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCoordinator\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "The title with the maximum IMDb rating is \"Scoobynatural\" with an IMDb score of 9.6.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:10][âœ… AGENT 'COORDINATOR\n",
      "' COMPLETED TASK]: 2025-03-10 20:46:10.896057\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:10][âœ… TASK COMPLETED: \n",
      "        ANALYZE THE DATA PRESENT AT HTTPS://RAW.GITHUBUSERCONTENT.COM/KERNELSHREYAK/AI-ML-LEARNING/REFS/HEADS/MASTER/DATASCIENCE/DATASETS/SCOOBYDOO.CSV AND PERFORM TASKS NECCESSARY TO ANSWER THE USER QUERY: USE THIS DATA AND FIND THE TITLE HAVING MAXMIUM IMDB RATING. USE COLUMN: IMDB\n",
      "    ]: 2025-03-10 20:46:10.896693\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-10 20:46:10][âœ… CREW 'CREW' COMPLETED, 70143AF7-BF89-467C-BFA1-54FFDB675E2E]: 2025-03-10 20:46:10.916216\u001b[00m\n",
      "response:  The title with the maximum IMDb rating is \"Scoobynatural\" with an IMDb score of 9.6.\n"
     ]
    }
   ],
   "source": [
    "# response = crew.kickoff(inputs={'user_query': 'Use this data and find the number of people who survived','data_source_url': '/home/shreyak/programming/agentic-data-query-engine/data/titanic.json'})\n",
    "response = crew.kickoff(inputs={'user_query': 'Use this data and find the title having maxmium imdb rating. Use column: imdb','data_source_url': 'https://raw.githubusercontent.com/kernelshreyak/ai-ml-learning/refs/heads/master/datascience/datasets/scoobydoo.csv'})\n",
    "print(\"response: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
